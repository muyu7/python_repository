# 第二章
1. elimination
   1. 我们得到n个非零的pivots,用回代法(back substitution)求解
   2. 没有得到n个非零的pivots,此时可能会求解失败
      1. 出现$0\neq0$时没有solution
      2. 出现$0=0$时,无数个解
   3. 在中途遇到0时,交换行
2. 用矩阵乘法(matrix multiplication)表示上面的消除操作
3. block multiplication:if blocks A can multiply blocks of B,then block multiplication of AB is allowd.Cuts between columns of A match cuts between rows of B.
   1. 左矩阵列的切割需要与右矩阵行切割匹配
   2. 把每个block当成一个矩阵entry就可以.
   3. 利用block idea理解消项过程:
      1. 第一列消项可以把n-1个elimination matrix合并成一个![](blockIdea%E7%AE%80%E5%8C%96elimination.png)注意这里只消除了第一列
4. inverse matrix
   1. $$BA=I,AC=I\\则BAC=IC\rightarrow B=C,即左逆矩阵等于右逆矩阵$$
   2. 已知BC=B,如果B是奇异矩阵,则C可以有无数个.如果B是非奇异矩阵,则C只有一个解--单位矩阵I.
      1. 举例$$\left(\begin{matrix}
      2&1\\0&0
      \end{matrix}\right)\left(\begin{matrix}
      1-\frac{a}{2}&\frac{1}{2}-\frac{b}{2}\\a&b
      \end{matrix}\right)=\left(\begin{matrix}
      2&1\\0&0
      \end{matrix}\right)$$a,b可以取任意值
      2. 更进一步,如果BC=BD,B是非奇异,则有C=D;B是奇异矩阵则不能得出C=D.
      3. 但是有个例外,如果BC=I,则B不会是奇异的,具体分析看下面4_2:存在逆
   3. $$已知BA=I,则BAB=B(AB)=IB=B\\根据上面的讨论,如果B是非奇异矩阵,则必定有AB=I,即B=A^{-1}$$
   4. 定理:the inverse exists if and only if dlimination produces n nonzero pivots(row exchanges are allowed).
      1. 第一步:n nonzero pivots 成立
         1. 假设B可以消项得到n nonzero pivots的三角矩阵C
         2. C通过类似的消项过程可以得到只有主对角线为非零元素的矩阵D,且在此过程中主对角线元不会出现0.
         3. 通过右乘这样的矩阵$$\left(\begin{matrix}
         1&0&0&\cdots\\0&m&0&\cdots\\\vdots&\vdots&\vdots&\ddots
         \end{matrix}\right)$$将对角矩阵D第二行元素变为1,重复同样的过程可以是D变为单位矩阵
         4. 通过结合律,所有elimination matrices相乘即有RB=I
         5. 因为B非奇异,所以R就是B的逆矩阵.
      2. 第二步:存在逆
         1. $AA^{-1}=I$,利用消项矩阵B左乘$AA^{-1}$可以将A变成上三角矩阵,同时r.h.s=BI,右消项过程可以,I在变换过程中主对角线元不会出现0.
         2. 假如消项后$BAA^{-1}=DA^{-1}$,D中最后一行全部为零,则左右两边不会相等,因为$(BI)_{nn}\neq0$
         3. 所以D主对角线元必须都不为零.
   5. 逆矩阵只能有一个
   6. suppose $\vec{x}\neq\vec{0}$ and $A\vec{x}=\vec{0}$,则A没有逆矩阵.
5. 求解逆矩阵:Guess-Jordan:$Multiply [A\ I]by\ A^{-1}$ to get [$I$ $A^{-1}$]
   1. 对扩展矩阵(augmented matrix)[A $I$]进行消项,当A变成I时,将得到[$I\ A^{-1}$]
6. 在不求解的情况下,判断可逆矩阵
   1. Diagonally dominant matrices are invertible.
7. 线性代数的很多关键问题,本质都是矩阵的因式分解(the factorizations of a matrices)
   1. $$A=LU$$L是消除矩阵乘积的逆矩阵,**注意这里的消除过程没有换行和行倍**.U是上三角矩阵,主对角线元是pivots,L是下三角矩阵,主对角线元都是1.
   2. $$A=LDU$$D是diagonal matrix,这种变形将使得U has 1's on the diagonal.
8. 转置矩阵
   1. $$(A+B)^T=A^T+B^T\\(AB)^T=B^TA^T\\(A^{-1})^T=(A^T)^{-1}$$
   2. $A^T$可逆等价于A可逆
9. 对称矩阵
   1.  对称矩阵都是方阵
   2.  对称矩阵的逆也是对称矩阵$$(S^{-1})^T=(S^T)^{-1}=S^{-1}$$
   3.  对称矩阵因式分解$$S=LDL^T$$<font color='red'>需要证明</font>
10. 排序矩阵(permutation matrix)
    1.  定义:排序矩阵是将单位矩阵行打乱的矩阵
    2.  n阶矩阵共有$n!$个排序矩阵
    3.  排序矩阵的逆
        1.  只有一次行变换的排序矩阵的逆是其本身
        2.  多次行变换的排序矩阵可以写成一次行变换矩阵的乘积的形式,逆就是倒序乘积
        3.  $$P^{-1}=P^T$$证明过程可以参考2,把任意P,写成基础P的乘积形式.

# 第三章
1. $R^n$空间定义:由所有包含n个分量的竖矢量组成的空间.
   1. 矢量的线性组合仍属于该空间.
   2. 一个向量空间需要定义所包含的向量和向量加法及数乘.并且规定运算需要满足的条件--封闭性.
   3. 唯一$\vec{0}$
   4. 唯一逆向量
2. 典型的向量空间
   1. M:all real 2 by 2 matrices.
   2. F: all real functions f(x).
   3. Z: consist only of a zero vector.
3. 列空间是由所有列的线性组合组成的.记作$C(A)$
4. 只有当b在A的列空间中时,$Ax=b$才是可解的.
5. 如果A是一个$m\times n$的矩阵,那么$C(A)$是$R^m$的子空间.
6. 创建子空间的方法除了上面提到的用方程组系数矩阵的列生成列空间外,还有一个很重要的方法:S是V空间中的一个向量集合.那么S中所有向量的线性组合将会生成一个V的子空间SS,SS是包含S的最小子空间.

## 3.2
1. 系数矩阵A($m\times n$)的零空间(the nullspace of A)N(A)由Ax=0的所有解组成.这些解n维的.很容易证明它们可以组成一个空间,且$N(A)\in R^n$
2. 对于$Ax=0$这样一个方程组
   1. 至少有一个解:$\vec{x}=\vec{0}$
   2. 将A转化为上三角矩阵时,pivots中有几个0,方程组的解就有几个自由量.
      1. 假设由h个自由量,分别对其中一个取1,剩余取0,并计算其余非自由变量就可以得到一个特解,总共由h个特解
      2. 对于$Ax=0$的任意一个解,可以根据后h个值由上面得到的h个特解的线性组合表示.很容易证明当线性组合满足后h个值得需要时,$\vec{x}$剩余得项也是可以满足的.即任意一个解都可以表示成上面h个特解的线性组合.
3. R矩阵(the reduced row echelon form R=rref(A)):对U矩阵进行一下两步
   1. 对pivot clounm向上消除
   2. 对每个pivot rows除以它自己的pivot,最后使得所有pivot都等于1,且pivot clounm的其他项都是0.
   3. 很明显第1步不会改变方程组的解集.第二步需要注意,当$\vec{b}=0$时,集解保持不变.所以有$$N(A)=N(U)=N(R)$$
4. 如果$N(A)$只包含$\vec{0}$,说明A的各列都是线性无关的.
5. 矩阵的阶(the rank of matrix)r:the rank of matrix A is the number of pivots.

# 名词汉译
1. factorization:因式分解
2. the transpose:转置矩阵
